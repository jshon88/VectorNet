{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1249efc4-281d-4e31-84dc-752322a604f2",
   "metadata": {},
   "source": [
    "# preprocess_data.py explanation and flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b076df-7401-4d1d-9e49-73fbdc2a5a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 81.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved features for 2645.csv\n",
      "Processed and saved features for 4791.csv\n",
      "Processed and saved features for 3700.csv\n",
      "Processed and saved features for 3861.csv\n",
      "Processed and saved features for 3828.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2020-05-27 15:00\n",
    "# @Author  : Xiaoke Huang\n",
    "# @Email   : xiaokehuang@foxmail.com\n",
    "# %%\n",
    "from utils.feature_utils import compute_feature_for_one_seq, encoding_features, save_features\n",
    "from argoverse.data_loading.argoverse_forecasting_loader import ArgoverseForecastingLoader\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from utils.config import DATA_DIR, LANE_RADIUS, OBJ_RADIUS, OBS_LEN, INTERMEDIATE_DATA_DIR\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    am = ArgoverseMap()\n",
    "    for folder in os.listdir(DATA_DIR):\n",
    "        if folder not in ['train', 'val', 'test']:\n",
    "            continue\n",
    "            \n",
    "        print(f\"folder: {folder}\")\n",
    "        afl = ArgoverseForecastingLoader(os.path.join(DATA_DIR, folder))\n",
    "        norm_center_dict = {}\n",
    "        for name in tqdm(afl.seq_list):\n",
    "            afl_ = afl.get(name)\n",
    "            path, name = os.path.split(name)\n",
    "            name, ext = os.path.splitext(name)\n",
    "\n",
    "            agent_feature, obj_feature_ls, lane_feature_ls, norm_center = compute_feature_for_one_seq(\n",
    "                afl_.seq_df, am, OBS_LEN, LANE_RADIUS, OBJ_RADIUS, viz=False, mode='nearby')\n",
    "            feature_df = encoding_features(\n",
    "                agent_feature, obj_feature_ls, lane_feature_ls)\n",
    "            save_features(feature_df, name, os.path.join(\n",
    "                INTERMEDIATE_DATA_DIR, f\"{folder}_intermediate\"))\n",
    "            print(f\"Processed and saved features for {name + '.csv'}\")\n",
    "\n",
    "            norm_center_dict[name] = norm_center\n",
    "        \n",
    "        with open(os.path.join(INTERMEDIATE_DATA_DIR, f\"{folder}-norm_center_dict.pkl\"), 'wb') as f:\n",
    "            pickle.dump(norm_center_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "            # print(pd.DataFrame(df['POLYLINE_FEATURES'].values[0]).describe())\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84798c2-af90-4fa8-abc1-2338e8bd9620",
   "metadata": {},
   "source": [
    "## 1. compute_feature_for_one_seq in feature_utils.py function explanation\n",
    "```\n",
    "compute_feature_for_one_seq(afl_.seq_df, am, OBS_LEN, LANE_RADIUS, OBJ_RADIUS, viz=False, mode='nearby')\n",
    "```\n",
    "\n",
    "- It is called inside the preprocess_data.py\n",
    "- This function converts raw data into feature representation for raw data.\n",
    "- In the VectorNet paper, they used first two seconds as observation and  2 - 5 seconds for trajectory prediction. so, OBS_LEN is 20 because each scenario consists of 5 seconds at 10 Hz, meaning that each timestamp is 0.1 second --> 20 sequences will be 2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25298f0-836a-4674-8e54-6382625cf6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_for_one_seq(traj_df: pd.DataFrame, am: ArgoverseMap, obs_len: int = 20, lane_radius: int = 5, obj_radius: int = 10, viz: bool = False, mode='rect', query_bbox=[-100, 100, -100, 100]) -> List[List]:\n",
    "    \"\"\"\n",
    "    return lane & track features\n",
    "    args:\n",
    "        mode: 'rect' or 'nearby'\n",
    "    returns:\n",
    "        agent_feature_ls:\n",
    "            list of (doubeld_track, object_type, timetamp, track_id, not_doubled_groudtruth_feature_trajectory)\n",
    "        obj_feature_ls:\n",
    "            list of list of (doubled_track, object_type, timestamp, track_id)\n",
    "        lane_feature_ls:\n",
    "            list of list of lane a segment feature, formatted in [left_lane, right_lane, is_traffic_control, is_intersection, lane_id]\n",
    "        norm_center np.ndarray: (2, )\n",
    "    \"\"\"\n",
    "    # normalize timestamps\n",
    "    traj_df['TIMESTAMP'] -= np.min(traj_df['TIMESTAMP'].values)\n",
    "    seq_ts = np.unique(traj_df['TIMESTAMP'].values)\n",
    "\n",
    "    seq_len = seq_ts.shape[0]\n",
    "    city_name = traj_df['CITY_NAME'].iloc[0]\n",
    "    agent_df = None\n",
    "    agent_x_end, agent_y_end, start_x, start_y, query_x, query_y, norm_center = [\n",
    "        None] * 7\n",
    "    # agent traj & its start/end point\n",
    "    for obj_type, remain_df in traj_df.groupby('OBJECT_TYPE'):\n",
    "        if obj_type == 'AGENT':\n",
    "            agent_df = remain_df\n",
    "            start_x, start_y = agent_df[['X', 'Y']].values[0]\n",
    "            agent_x_end, agent_y_end = agent_df[['X', 'Y']].values[-1]\n",
    "            query_x, query_y = agent_df[['X', 'Y']].values[obs_len-1]\n",
    "            norm_center = np.array([query_x, query_y])\n",
    "            break\n",
    "        else:\n",
    "            raise ValueError(f\"cannot find 'agent' object type\")\n",
    "\n",
    "    # prune points after \"obs_len\" timestamp\n",
    "    # [FIXED] test set length is only `obs_len`\n",
    "    traj_df = traj_df[traj_df['TIMESTAMP'] <=\n",
    "                      agent_df['TIMESTAMP'].values[obs_len-1]]\n",
    "\n",
    "    assert (np.unique(traj_df[\"TIMESTAMP\"].values).shape[0]\n",
    "            == obs_len), \"Obs len mismatch\"\n",
    "\n",
    "    # search nearby lane from the last observed point of agent\n",
    "    # FIXME: nearby or rect?\n",
    "    # lane_feature_ls = get_nearby_lane_feature_ls(\n",
    "    #     am, agent_df, obs_len, city_name, lane_radius, norm_center)\n",
    "    lane_feature_ls = get_nearby_lane_feature_ls(\n",
    "        am, agent_df, obs_len, city_name, lane_radius, norm_center, mode=mode, query_bbox=query_bbox)\n",
    "    # pdb.set_trace()\n",
    "\n",
    "    # search nearby moving objects from the last observed point of agent\n",
    "    obj_feature_ls = get_nearby_moving_obj_feature_ls(\n",
    "        agent_df, traj_df, obs_len, seq_ts, norm_center)\n",
    "    # get agent features\n",
    "    agent_feature = get_agent_feature_ls(agent_df, obs_len, norm_center)\n",
    "\n",
    "    # vis\n",
    "    if viz:\n",
    "        for features in lane_feature_ls:\n",
    "            show_doubled_lane(\n",
    "                np.vstack((features[0][:, :2], features[0][-1, 3:5])))\n",
    "            show_doubled_lane(\n",
    "                np.vstack((features[1][:, :2], features[1][-1, 3:5])))\n",
    "        for features in obj_feature_ls:\n",
    "            show_traj(\n",
    "                np.vstack((features[0][:, :2], features[0][-1, 2:])), features[1])\n",
    "        show_traj(np.vstack(\n",
    "            (agent_feature[0][:, :2], agent_feature[0][-1, 2:])), agent_feature[1])\n",
    "\n",
    "        plt.plot(agent_x_end - query_x, agent_y_end - query_y, 'o',\n",
    "                 color=color_dict['AGENT'], markersize=7)\n",
    "        plt.plot(0, 0, 'x', color='blue', markersize=4)\n",
    "        plt.plot(start_x-query_x, start_y-query_y,\n",
    "                 'x', color='blue', markersize=4)\n",
    "        plt.show()\n",
    "\n",
    "    return [agent_feature, obj_feature_ls, lane_feature_ls, norm_center]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2a5db94-137d-4746-b456-9c4689ed62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "767e9fad-e73c-43e1-902e-0d539cf02913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBS_LEN: 20\n",
      "LANE_RADIUS: 30\n",
      "OBJ_RADIUS: 30\n",
      "      TIMESTAMP                              TRACK_ID OBJECT_TYPE           X  \\\n",
      "0       0.00000  00000000-0000-0000-0000-000000000000          AV  598.663624   \n",
      "1       0.00000  00000000-0000-0000-0000-000000051661      OTHERS  618.404171   \n",
      "2       0.00000  00000000-0000-0000-0000-000000051798      OTHERS  582.502438   \n",
      "3       0.00000  00000000-0000-0000-0000-000000051757      OTHERS  650.240829   \n",
      "4       0.00000  00000000-0000-0000-0000-000000051599      OTHERS  595.241947   \n",
      "...         ...                                   ...         ...         ...   \n",
      "1038    4.89916  00000000-0000-0000-0000-000000051894      OTHERS  596.621870   \n",
      "1039    4.89916  00000000-0000-0000-0000-000000051639       AGENT  602.637295   \n",
      "1040    4.89916  00000000-0000-0000-0000-000000051889      OTHERS  597.087316   \n",
      "1041    4.89916  00000000-0000-0000-0000-000000051771      OTHERS  594.939561   \n",
      "1042    4.89916  00000000-0000-0000-0000-000000051632      OTHERS  595.080182   \n",
      "\n",
      "               Y CITY_NAME  \n",
      "0     811.841476       MIA  \n",
      "1     830.296757       MIA  \n",
      "2     832.904074       MIA  \n",
      "3     829.619755       MIA  \n",
      "4     881.123553       MIA  \n",
      "...          ...       ...  \n",
      "1038  747.008772       MIA  \n",
      "1039  770.902090       MIA  \n",
      "1040  740.554727       MIA  \n",
      "1041  791.708545       MIA  \n",
      "1042  798.272420       MIA  \n",
      "\n",
      "[1043 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print('OBS_LEN:', OBS_LEN)\n",
    "print('LANE_RADIUS:', LANE_RADIUS)\n",
    "print('OBJ_RADIUS:', OBJ_RADIUS)\n",
    "    \n",
    "afl = ArgoverseForecastingLoader(os.path.join(DATA_DIR, folder))\n",
    "for name in tqdm(afl.seq_list):\n",
    "    afl_ = afl.get(name) # returns ArgoverseForecastingLoader object that reads .csv file\n",
    "    \n",
    "traj_df = afl_.seq_df # basically it is Dataframe of the csv file\n",
    "am = ArgoverseMap()\n",
    "obs_len = OBS_LEN\n",
    "lane_radius = LANE_RADIUS\n",
    "obj_radius = OBJ_RADIUS\n",
    "mode = 'nearby' # 'nearby' or 'rect'\n",
    "query_bbox = [-100, 100, -100, 100]\n",
    "\n",
    "print(traj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc1a83cf-8fd8-45de-8f29-da8311351bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized timestamp: \n",
      " [0.         0.10002953 0.19654495 0.29651338 0.39852524 0.50251335\n",
      " 0.60243654 0.69699281 0.79970425 0.89752984 1.00244039 1.09576762\n",
      " 1.19675922 1.29768014 1.39789224 1.49737501 1.59750032 1.69619334\n",
      " 1.8003788  1.90153521 2.0120312  2.09697974 2.19333982 2.29298574\n",
      " 2.40065807 2.49518925 2.59894401 2.69540894 2.79657811 2.89352387\n",
      " 3.00350517 3.09673125 3.19999939 3.29636294 3.40343642 3.49622393\n",
      " 3.59391522 3.69679397 3.80828524 3.89221054 3.99273527 4.08895117\n",
      " 4.18673015 4.29252023 4.39606696 4.49331379 4.59667361 4.69836873\n",
      " 4.80369681 4.89915991]\n",
      "sequence length: 50\n"
     ]
    }
   ],
   "source": [
    "# Time Normalization so that the sequence starts at 0\n",
    "traj_df['TIMESTAMP'] -= np.min(traj_df['TIMESTAMP'].values)\n",
    "seq_ts = np.unique(traj_df['TIMESTAMP'].values)\n",
    "seq_len = seq_ts.shape[0]\n",
    "\n",
    "print('Normalized timestamp: \\n', seq_ts)\n",
    "print('sequence length:', seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3f9e35c-ba71-44fd-98c4-f8a6456af74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = traj_df['CITY_NAME'].iloc[0]\n",
    "agent_df = None\n",
    "agent_x_end, agent_y_end, start_x, start_y, query_x, query_y, norm_center = [None] * 7\n",
    "\n",
    "for obj_type, remain_df in traj_df.groupby('OBJECT_TYPE'):\n",
    "    if obj_type == 'AGENT':\n",
    "        agent_df = remain_df\n",
    "        start_x, start_y = agent_df[['X', 'Y']].values[0]\n",
    "        agent_x_end, agent_y_end = agent_df[['X', 'Y']].values[-1]\n",
    "        query_x, query_y = agent_df[['X', 'Y']].values[obs_len-1]\n",
    "        norm_center = np.array([query_x, query_y])\n",
    "traj_df = traj_df[traj_df['TIMESTAMP'] <= agent_df['TIMESTAMP'].values[obs_len-1]]\n",
    "assert (np.unique(traj_df[\"TIMESTAMP\"].values).shape[0] == obs_len), \"Obs len mismatch\"\n",
    "# this function is explained below\n",
    "lane_feature_ls = get_nearby_lane_feature_ls(am, agent_df, obs_len, city_name, lane_radius, norm_center, mode=mode, query_bbox=query_bbox)\n",
    "# this function is explained below\n",
    "obj_feature_ls = get_nearby_moving_obj_feature_ls(agent_df, traj_df, obs_len, seq_ts, norm_center)\n",
    "# this function is explained below\n",
    "agent_feature = get_agent_feature_ls(agent_df, obs_len, norm_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f5c33a-b55a-4c1e-9392-3ad8816dc555",
   "metadata": {},
   "source": [
    "### 1.1 get_nearby_lane_feature_ls function in lane_utils.py\n",
    "```\n",
    "get_nearby_lane_feature_ls(am, agent_df, obs_len, city_name, lane_radius, norm_center, mode=mode, query_bbox=query_bbox)\n",
    "```\n",
    "- This is called inside compute_feature_for_one_seq function as it computes lane features\n",
    "- computes lane features\n",
    "- centerlane consists of multiple x, y, z coordinates where z is nan, so it's 2D coordinates acutally. centerlane coordinate is extracted from argoverse-api with lane_id as a key. So, assume centerlane is a polygon, a list of [x, y] center coordinate of the lane. So, this list of [x, y] represents a \"way\" of a road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1ebe23b-ef8d-4005-b93f-36dc076aa57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_lane_feature_ls(am, agent_df, obs_len, city_name, lane_radius, norm_center, has_attr=False, mode='nearby', query_bbox=None):\n",
    "    '''\n",
    "    compute lane features\n",
    "    args:\n",
    "        norm_center: np.ndarray\n",
    "        mode: 'nearby' return nearby lanes within the radius; 'rect' return lanes within the query bbox\n",
    "        **kwargs: query_bbox= List[int, int, int, int]\n",
    "    returns:\n",
    "        list of list of lane a segment feature, formatted in [left_lane, right_lane, is_traffic_control, is_intersection, lane_id]\n",
    "    '''\n",
    "    lane_feature_ls = []\n",
    "    if mode == 'nearby':\n",
    "        query_x, query_y = agent_df[['X', 'Y']].values[obs_len-1]\n",
    "        nearby_lane_ids = am.get_lane_ids_in_xy_bbox(query_x, query_y, city_name, lane_radius) # returns lane ids in [query_x - 5, query_y - 5, query_x + 5, query_y + 5]\n",
    "        for lane_id in nearby_lane_ids:\n",
    "            traffic_control = am.lane_has_traffic_control_measure(lane_id, city_name) # return Bool\n",
    "            is_intersection = am.lane_is_in_intersection(lane_id, city_name) # returns Bool\n",
    "            centerlane = am.get_lane_segment_centerline(lane_id, city_name)\n",
    "            # normalize to last observed timestamp point of agent\n",
    "            centerlane[:, :2] -= norm_center\n",
    "            halluc_lane_1, halluc_lane_2 = get_halluc_lane(centerlane, city_name)\n",
    "            lane_feature_ls.append([halluc_lane_1, halluc_lane_2, traffic_control, is_intersection, lane_id])\n",
    "    return lane_feature_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2da0179-f4b1-4480-a3e6-695bb9779664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-28.58607131,   6.75708774,          nan],\n",
       "       [-26.86963019,   6.82157199,          nan],\n",
       "       [-25.15344902,   6.89267061,          nan],\n",
       "       [-23.43726786,   6.96376923,          nan],\n",
       "       [-21.72108669,   7.03486786,          nan],\n",
       "       [-20.00490553,   7.10596648,          nan],\n",
       "       [-18.28927696,   7.18927595,          nan],\n",
       "       [-16.57365677,   7.27277024,          nan],\n",
       "       [-14.85803657,   7.35626453,          nan],\n",
       "       [-13.14241637,   7.43975882,          nan]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centerlane # normalized based on last observed timestamp point of agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922474a0-afd0-48a4-9228-0fa9f2c3141c",
   "metadata": {},
   "source": [
    "#### 1.1.1 get_halluc_lane function in lane_utils.py\n",
    "\n",
    "```\n",
    "get_halluc_lane(centerlane, city_name)\n",
    "```\n",
    "- This is called inside the get_nearby_lane_feature_ls function\n",
    "- It creates hallucinated coordinates that could be left and right boundaries (edgs) of the lane\n",
    "- These edges coordinates are calculated by the following:\n",
    "    - calculate dx by substracting two consecutive centerline coordinates: a direction from st to en\n",
    "    - normalizes dx by norm(dx): unit vector in the direction\n",
    "    - rotate_quat: 90 degree counter clockwise rotation\n",
    "    - e1 = rotate_quat @ dx / norm: 90 degree counter clockwise rotation of the unit vector (used to infer left edge)\n",
    "    - e2 = rotate_quat.T @ dx / norm: 90 degree clockwise rotation, same as -e1\n",
    "    - lane_1: adding e1 to st and en, referring left lane boundary\n",
    "    - lane_2: adding e1 to st and en, referring right lane boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51afe02d-d008-4d5a-8c7a-9debaddc6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import LANE_WIDTH\n",
    "def get_halluc_lane(centerlane, city_name):\n",
    "    \"\"\"\n",
    "    return left & right lane based on centerline\n",
    "    args:\n",
    "    returns:\n",
    "        doubled_left_halluc_lane, doubled_right_halluc_lane, shaped in (N-1, 3)\n",
    "    \"\"\"\n",
    "    if centerlane.shape[0] <= 1:\n",
    "        raise ValueError('shape of centerlane error.')\n",
    "\n",
    "    half_width = LANE_WIDTH[city_name] / 2 # LANE_WIDTH = {'MIA': 3.84, 'PIT': 3.97}\n",
    "    rotate_quat = np.array([[0.0, -1.0], [1.0, 0.0]])\n",
    "    halluc_lane_1, halluc_lane_2 = np.empty(\n",
    "        (0, centerlane.shape[1]*2)), np.empty((0, centerlane.shape[1]*2))\n",
    "    for i in range(centerlane.shape[0]-1):\n",
    "        st, en = centerlane[i][:2], centerlane[i+1][:2]\n",
    "        dx = en - st # direction from st to en\n",
    "        norm = np.linalg.norm(dx) # basically euclidean distance between two centerpoint\n",
    "        # dx / norm : normalizes dx to get a unit vector in the direction from st to en\n",
    "        # roate_quat : standard 90 degree rotation matrix\n",
    "        # So, e1 rotates 90 degree cocunter clockwise, and e2 is direct opposite of e1, which is 90 degree clock wise from the original, dx / norm\n",
    "        e1, e2 = rotate_quat @ dx / norm, rotate_quat.T @ dx / norm # basically e2 = - e1\n",
    "        lane_1 = np.hstack(\n",
    "            (st + e1 * half_width, centerlane[i][2], en + e1 * half_width, centerlane[i+1][2]))\n",
    "        lane_2 = np.hstack(\n",
    "            (st + e2 * half_width, centerlane[i][2], en + e2 * half_width, centerlane[i+1][2]))\n",
    "        # print(halluc_lane_1, )\n",
    "        halluc_lane_1 = np.vstack((halluc_lane_1, lane_1))\n",
    "        halluc_lane_2 = np.vstack((halluc_lane_2, lane_2))\n",
    "    return halluc_lane_1, halluc_lane_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "10009078-ea6e-4290-9bef-35880d1d95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_quat = np.array([[0.0, -1.0], [1.0, 0.0]])\n",
    "st, en = centerlane[0][:2], centerlane[0+1][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4202449a-2e8d-4448-be89-24f507add006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st: [-28.58607131   6.75708774]\n",
      "end: [-26.86963019   6.82157199]\n"
     ]
    }
   ],
   "source": [
    "print('st:', st)\n",
    "print('end:', en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2eaaeaf1-cd51-4ec7-9bb1-9114c8d64ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-26.86963019,   6.82157199])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff37ef9a-4992-4c47-be4f-e25424cd5c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.71644112, 0.06448424])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx = en - st\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46389f11-a2f4-449a-ad96-8af9558adac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7176519818435505"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = np.linalg.norm(dx)\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6e39a-551f-4a24-a462-8c8ee881de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_quat = np.array([[0.0, -1.0], [1.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb6e27eb-a297-4cc2-a6a9-7c795a33c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = rotate_quat @ dx / norm, rotate_quat.T @ dx / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c604e15-370f-4c76-a9c4-f0ba2993d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1:  [-0.03754209  0.99929505]\n",
      "e2:  [ 0.03754209 -0.99929505]\n"
     ]
    }
   ],
   "source": [
    "print('e1: ', e1)\n",
    "print('e2: ', e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1af380a6-380e-4454-b5d0-e77df678d843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99929505, 0.03754209])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb69d0d-59a7-4a97-a123-a218c4b66915",
   "metadata": {},
   "source": [
    "### 1.2 get_nearby_moving_obj_feature_ls function in object_utils.py\n",
    "```\n",
    "get_nearby_moving_obj_feature_ls(agent_df, traj_df, obs_len, seq_ts, norm_center)\n",
    "```\n",
    "- this function is called inside compute_feature_for_one_seq\n",
    "- computes features of nearby moving objects\n",
    "- I fixed EXIST_THRESHOLD value to be 10 from 50 because traj_df is already pruned by 20 timesteps as first 2 seconds are used for observations, and therefore, setting the threshold as 50 timesteps will return empty list because any moving object total timesteps will always be <= 20. So, appearing at least 50% of total timesteps, which is 10, would be reasonable threshold by convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "435f97ca-300c-4e1a-ae33-81abe9dffe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import EXIST_THRESHOLD, OBJ_RADIUS\n",
    "\n",
    "def get_nearby_moving_obj_feature_ls(agent_df, traj_df, obs_len, seq_ts, norm_center):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    returns: list of list, (doubled_track, object_type, timestamp, track_id)\n",
    "    \"\"\"\n",
    "    obj_feature_ls = []\n",
    "    query_x, query_y = agent_df[['X', 'Y']].values[obs_len-1]\n",
    "    p0 = np.array([query_x, query_y])\n",
    "    for track_id, remain_df in traj_df.groupby('TRACK_ID'):\n",
    "        if remain_df['OBJECT_TYPE'].iloc[0] == 'AGENT':\n",
    "            continue\n",
    "\n",
    "        if len(remain_df) < EXIST_THRESHOLD or get_is_track_stationary(remain_df):\n",
    "            continue\n",
    "\n",
    "        xys, ts = None, None\n",
    "\n",
    "        xys = remain_df[['X', 'Y']].values # other object coordinates\n",
    "        ts = remain_df[\"TIMESTAMP\"].values\n",
    "\n",
    "        p1 = xys[-1] # most recent coordinate\n",
    "        if np.linalg.norm(p0 - p1) > OBJ_RADIUS: # distance from ego position to other object\n",
    "            continue\n",
    "\n",
    "        xys -= norm_center  # normalize to last observed timestamp point of agent\n",
    "        xys = np.hstack((xys[:-1], xys[1:])) # [[first xy, second xy], [second xy, third xy], ...]\n",
    "        \n",
    "        ts = (ts[:-1] + ts[1:]) / 2 # [(first stamp + second stamp) / 2, (second + third) / 2 , ...]\n",
    "\n",
    "        obj_feature_ls.append(\n",
    "            [xys, remain_df['OBJECT_TYPE'].iloc[0], ts, track_id])\n",
    "    return obj_feature_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c794b155-f517-442b-b071-c78e0b12d4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXIST_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "875394fa-72c8-4bd9-9c8f-c5f0f2330934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>TRACK_ID</th>\n",
       "      <th>OBJECT_TYPE</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>CITY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1.696193</td>\n",
       "      <td>00000000-0000-0000-0000-000000051876</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>595.366076</td>\n",
       "      <td>855.053742</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.800379</td>\n",
       "      <td>00000000-0000-0000-0000-000000051876</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>595.432209</td>\n",
       "      <td>854.998254</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1.901535</td>\n",
       "      <td>00000000-0000-0000-0000-000000051876</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>595.231849</td>\n",
       "      <td>855.070501</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TIMESTAMP                              TRACK_ID OBJECT_TYPE           X  \\\n",
       "371   1.696193  00000000-0000-0000-0000-000000051876      OTHERS  595.366076   \n",
       "391   1.800379  00000000-0000-0000-0000-000000051876      OTHERS  595.432209   \n",
       "412   1.901535  00000000-0000-0000-0000-000000051876      OTHERS  595.231849   \n",
       "\n",
       "              Y CITY_NAME  \n",
       "371  855.053742       MIA  \n",
       "391  854.998254       MIA  \n",
       "412  855.070501       MIA  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e051ba0-06f3-412f-a174-1a6c91b5ad35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OBJ_RADIUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d0010235-562b-4a95-88be-cef57fe04cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.68409285, 39.74868874, -6.6179599 , 39.69320097],\n",
       "       [-6.6179599 , 39.69320097, -6.81831994, 39.76544813]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f945d4c-08cc-4406-9972-c81c0bf48195",
   "metadata": {},
   "source": [
    "#### 1.2.1 get_is_track_stationary function in object_utils.py\n",
    "```\n",
    "get_is_track_stationary(remain_df)\n",
    "```\n",
    "- this function is called inside the get_nearby_moving_obj_feature_ls\n",
    "- this function checks if the track is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3cacaeaa-f497-4ad8-b173-05bd647dd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import VELOCITY_THRESHOLD\n",
    "def get_is_track_stationary(track_df: pd.DataFrame) -> bool:\n",
    "    \"\"\"Check if the track is stationary.\n",
    "\n",
    "    Args:\n",
    "        track_df (pandas Dataframe): Data for the track\n",
    "    Return:\n",
    "        _ (bool): True if track is stationary, else False\n",
    "\n",
    "    \"\"\"\n",
    "    vel = compute_velocity(track_df) # velocity computed using consecutive [x, y] coordinates\n",
    "    sorted_vel = sorted(vel)\n",
    "    threshold_vel = sorted_vel[int(len(vel) / 2)] # roughly median of velocity values\n",
    "    return True if threshold_vel < VELOCITY_THRESHOLD else False # VELOCITY_THRESHOLD set as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3cdbd0b-df70-4415-ad1f-c2f243fe52bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VELOCITY_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "54fe227d-b73a-494f-b664-b0963dc767e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8958.634324644798, 9258.071129962122]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784b11c-93f9-4134-893a-40afef5947af",
   "metadata": {},
   "source": [
    "### 1.3 get_agent_feature_ls function in agent_utils.py\n",
    "```\n",
    "get_agent_feature_ls(agent_df, obs_len, norm_center)\n",
    "```\n",
    "- this function is called inside compute_feature_for_one_seq function\n",
    "- computes agent features\n",
    "- returns [xys, object_type, ts, track_id, gt_xys] where xys in the from of [xs, ys, xe, ye] for vetor representation, ts is average timestamp of consecutive coordinates representing each segment ([xs, ys, xe, ye]), gt_xys is [xs, ys, xe, ye] for last 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86789914-ef40-4420-b4f8-96cf44ef0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_feature_ls(agent_df, obs_len, norm_center):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    returns: \n",
    "        list of (doubeld_track, object_type, timetamp, track_id, not_doubled_groudtruth_feature_trajectory)\n",
    "    \"\"\"\n",
    "    xys, gt_xys = agent_df[[\"X\", \"Y\"]].values[:obs_len], agent_df[[\n",
    "        \"X\", \"Y\"]].values[obs_len:]\n",
    "    xys -= norm_center  # normalize to last observed timestamp point of agent\n",
    "    gt_xys -= norm_center  # normalize to last observed timestamp point of agent\n",
    "    xys = np.hstack((xys[:-1], xys[1:]))\n",
    "\n",
    "    ts = agent_df['TIMESTAMP'].values[:obs_len]\n",
    "    ts = (ts[:-1] + ts[1:]) / 2\n",
    "\n",
    "    return [xys, agent_df['OBJECT_TYPE'].iloc[0], ts, agent_df['TRACK_ID'].iloc[0], gt_xys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d31fd-4dc3-430d-aaf6-e215171ef620",
   "metadata": {},
   "source": [
    "## 2. encoding_features in feature_utils.py function explanation\n",
    "```\n",
    "encoding_features(agent_feature, obj_feature_ls, lane_feature_ls)\n",
    "```\n",
    "\n",
    "- It is called inside the preprocess_data.py\n",
    "- agent_feature: list of (doubeld_track, object_type, timestamp, track_id, not_doubled_groudtruth_feature_trajectory)\n",
    "    - [ [xs, ys, xe, ye], 'AGENT', ts, track_id ]\n",
    "- obj_feature_ls: list of list of (doubled_track, object_type, timestamp, track_id)\n",
    "    - [ [obect 1 features], [object 2 features] ] where each object features = [ [xs, ys, xe, ye], 'object_type', ts, track_id ]\n",
    "- lane_feature_ls: list of list of lane a segment feature, formatted in [left_lane, right_lane, is_traffic_control, is_intersection, lane_id]\n",
    "- This function takes the above arguments and creates polyline features.\n",
    "    - for agent and objects: array(xs, ys, xe, ye, object_type, ts, polyline_id)\n",
    "    - for lane: array(xs, ys, zs, xe, ye, ze, polyline_id)\n",
    "- Then, to concatenate these two ppolyline features, do the following trick:\n",
    "    - change agent and object polyline features to (xs, ys, xe, ye, timestamp, NULL, NULL, polyline_id). Here object_type no longer exists\n",
    "    - change lane polyline features to (xs, ys, xe, ye, NULL, zs, ze, polyline_id)\n",
    "    - Then concat in vertical stack way\n",
    "- Finally, returns dataframe of [polyline_features, offset_gt, traj_id2mask, lane_id2mask, traj_nd.shape[0], lane_nd.shape[0]]\n",
    "    - offset_gt is last 3seconds gt coordinates offset from last observed point. Basically gt[1] - gt[0], ...\n",
    "    - traj_id2mask is a dict that takes polyline_id as a key and (previous length, current length) as value. previous length is agent and object polyline features shape[0] without current object shape[0] added. current length is after current object shape[0] added\n",
    "    - lane_id2mask is the same but for lane\n",
    "    - traj_nd.shape[0] is total polyline features length for all the objects and ego vehicle(agent)\n",
    "    - lane_nd.shape[0] is the same for lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06d060-9765-4915-8ec0-29d8e3455c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_features(agent_feature, obj_feature_ls, lane_feature_ls):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        agent_feature_ls:\n",
    "            list of (doubeld_track, object_type, timestamp, track_id, not_doubled_groudtruth_feature_trajectory)\n",
    "        obj_feature_ls:\n",
    "            list of list of (doubled_track, object_type, timestamp, track_id)\n",
    "        lane_feature_ls:\n",
    "            list of list of lane a segment feature, formatted in [left_lane, right_lane, is_traffic_control, is_intersection, lane_id]\n",
    "    returns:\n",
    "        pd.DataFrame of (\n",
    "            polyline_features: vstack[\n",
    "                (xs, ys, xe, ye, timestamp, NULL, NULL, polyline_id),\n",
    "                (xs, ys, xe, ye, NULL, zs, ze, polyline_id)\n",
    "                ]\n",
    "            offset_gt: incremental offset from agent's last obseved point,\n",
    "            traj_id2mask: Dict[int, int]\n",
    "            lane_id2mask: Dict[int, int]\n",
    "        )\n",
    "        where obejct_type = {0 - others, 1 - agent}\n",
    "\n",
    "    \"\"\"\n",
    "    polyline_id = 0\n",
    "    traj_id2mask, lane_id2mask = {}, {}\n",
    "    gt = agent_feature[-1]\n",
    "    traj_nd, lane_nd = np.empty((0, 7)), np.empty((0, 7))\n",
    "\n",
    "    # encoding agent feature\n",
    "    pre_traj_len = traj_nd.shape[0]\n",
    "    agent_len = agent_feature[0].shape[0]\n",
    "    # print(agent_feature[0].shape, np.ones(\n",
    "    # (agent_len, 1)).shape, agent_feature[2].shape, (np.ones((agent_len, 1)) * polyline_id).shape)\n",
    "    agent_nd = np.hstack((agent_feature[0], np.ones(\n",
    "        (agent_len, 1)), agent_feature[2].reshape((-1, 1)), np.ones((agent_len, 1)) * polyline_id))\n",
    "    assert agent_nd.shape[1] == 7, \"obj_traj feature dim 1 is not correct\"\n",
    "\n",
    "    traj_nd = np.vstack((traj_nd, agent_nd))\n",
    "    traj_id2mask[polyline_id] = (pre_traj_len, traj_nd.shape[0])\n",
    "    pre_traj_len = traj_nd.shape[0]\n",
    "    polyline_id += 1\n",
    "\n",
    "    # encoding obj feature\n",
    "    for obj_feature in obj_feature_ls:\n",
    "        obj_len = obj_feature[0].shape[0]\n",
    "        # assert obj_feature[2].shape[0] == obj_len, f\"obs_len of obj is {obj_len}\"\n",
    "        if not obj_feature[2].shape[0] == obj_len:\n",
    "            from pdb import set_trace;set_trace()\n",
    "        obj_nd = np.hstack((obj_feature[0], np.zeros(\n",
    "            (obj_len, 1)), obj_feature[2].reshape((-1, 1)), np.ones((obj_len, 1)) * polyline_id))\n",
    "        assert obj_nd.shape[1] == 7, \"obj_traj feature dim 1 is not correct\"\n",
    "        traj_nd = np.vstack((traj_nd, obj_nd))\n",
    "\n",
    "        traj_id2mask[polyline_id] = (pre_traj_len, traj_nd.shape[0])\n",
    "        pre_traj_len = traj_nd.shape[0]\n",
    "        polyline_id += 1\n",
    "\n",
    "    # incodeing lane feature\n",
    "    pre_lane_len = lane_nd.shape[0]\n",
    "    for lane_feature in lane_feature_ls:\n",
    "        l_lane_len = lane_feature[0].shape[0]\n",
    "        l_lane_nd = np.hstack(\n",
    "            (lane_feature[0], np.ones((l_lane_len, 1)) * polyline_id))\n",
    "        assert l_lane_nd.shape[1] == 7, \"obj_traj feature dim 1 is not correct\"\n",
    "        lane_nd = np.vstack((lane_nd, l_lane_nd))\n",
    "        lane_id2mask[polyline_id] = (pre_lane_len, lane_nd.shape[0])\n",
    "        _tmp_len_1 = pre_lane_len - lane_nd.shape[0]\n",
    "        pre_lane_len = lane_nd.shape[0]\n",
    "        polyline_id += 1\n",
    "\n",
    "        r_lane_len = lane_feature[1].shape[0]\n",
    "        r_lane_nd = np.hstack(\n",
    "            (lane_feature[1], np.ones((r_lane_len, 1)) * polyline_id)\n",
    "        )\n",
    "        assert r_lane_nd.shape[1] == 7, \"obj_traj feature dim 1 is not correct\"\n",
    "        lane_nd = np.vstack((lane_nd, r_lane_nd))\n",
    "        lane_id2mask[polyline_id] = (pre_lane_len, lane_nd.shape[0])\n",
    "        _tmp_len_2 = pre_lane_len - lane_nd.shape[0]\n",
    "        pre_lane_len = lane_nd.shape[0]\n",
    "        polyline_id += 1\n",
    "\n",
    "        assert _tmp_len_1 == _tmp_len_2, f\"left, right lane vector length contradict\"\n",
    "        # lane_nd = np.vstack((lane_nd, l_lane_nd, r_lane_nd))\n",
    "\n",
    "    # FIXME: handling `nan` in lane_nd\n",
    "    col_mean = np.nanmean(lane_nd, axis=0)\n",
    "    if np.isnan(col_mean).any():\n",
    "        # raise ValueError(\n",
    "        # print(f\"{col_mean}\\nall z (height) coordinates are `nan`!!!!\")\n",
    "        lane_nd[:, 2].fill(.0)\n",
    "        lane_nd[:, 5].fill(.0)\n",
    "    else:\n",
    "        inds = np.where(np.isnan(lane_nd))\n",
    "        lane_nd[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "    # traj_ls, lane_ls = reconstract_polyline(\n",
    "    #     np.vstack((traj_nd, lane_nd)), traj_id2mask, lane_id2mask, traj_nd.shape[0])\n",
    "    # type_ = 'AGENT'\n",
    "    # for traj in traj_ls:\n",
    "    #     show_traj(traj, type_)\n",
    "    #     type_ = 'OTHERS'\n",
    "\n",
    "    # for lane in lane_ls:\n",
    "    #     show_doubled_lane(lane)\n",
    "    # plt.show()\n",
    "\n",
    "    # transform gt to offset_gt\n",
    "    offset_gt = trans_gt_offset_format(gt)\n",
    "\n",
    "    # now the features are:\n",
    "    # (xs, ys, xe, ye, obejct_type, timestamp(avg_for_start_end?),polyline_id) for object\n",
    "    # (xs, ys, zs, xe, ye, ze, polyline_id) for lanes\n",
    "\n",
    "    # change lanes feature to xs, ys, xe, ye, NULL, zs, ze, polyline_id)\n",
    "    lane_nd = np.hstack(\n",
    "        [lane_nd, np.zeros((lane_nd.shape[0], 1), dtype=lane_nd.dtype)])\n",
    "    lane_nd = lane_nd[:, [0, 1, 3, 4, 7, 2, 5, 6]]\n",
    "    # change object features to (xs, ys, xe, ye, timestamp, NULL, NULL, polyline_id)\n",
    "    traj_nd = np.hstack(\n",
    "        [traj_nd, np.zeros((traj_nd.shape[0], 2), dtype=traj_nd.dtype)])\n",
    "    traj_nd = traj_nd[:, [0, 1, 2, 3, 5, 7, 8, 6]]\n",
    "\n",
    "    # don't ignore the id\n",
    "    polyline_features = np.vstack((traj_nd, lane_nd))\n",
    "    data = [[polyline_features.astype(\n",
    "        np.float32), offset_gt, traj_id2mask, lane_id2mask, traj_nd.shape[0], lane_nd.shape[0]]]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\"POLYLINE_FEATURES\", \"GT\",\n",
    "                 \"TRAJ_ID_TO_MASK\", \"LANE_ID_TO_MASK\", \"TARJ_LEN\", \"LANE_LEN\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3bbe51e8-69ba-4194-8682-0fab2ec03785",
   "metadata": {},
   "outputs": [],
   "source": [
    "polyline_id = 0\n",
    "traj_id2mask, lane_id2mask = {}, {}\n",
    "gt = agent_feature[-1] # last 3 seconds x,y coordinates\n",
    "traj_nd, lane_nd = np.empty((0, 7)), np.empty((0, 7)) # returns the shape of array without initializing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "79791fb7-3d34-4de9-a4b5-92b5f04c526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt shape:  (30, 2)\n",
      "traj_nd shape:  (0, 7)\n"
     ]
    }
   ],
   "source": [
    "print('gt shape: ', gt.shape)\n",
    "print('traj_nd shape: ',traj_nd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1e0b8f92-39d9-420c-9bf3-72b7d8eff36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_traj_len = traj_nd.shape[0]\n",
    "agent_len = agent_feature[0].shape[0]\n",
    "# agent_feature[0] : xys, [xs, ys, xe, ye]\n",
    "# agent_feature[2] : representative timestamp for each segment\n",
    "agent_nd = np.hstack((agent_feature[0], np.ones((agent_len, 1)), agent_feature[2].reshape((-1, 1)), np.ones((agent_len, 1)) * polyline_id))\n",
    "assert agent_nd.shape[1] == 7, \"obj_traj feature dim 1 is not correct\"\n",
    "\n",
    "traj_nd = np.vstack((traj_nd, agent_nd))\n",
    "traj_id2mask[polyline_id] = (pre_traj_len, traj_nd.shape[0])\n",
    "pre_traj_len = traj_nd.shape[0]\n",
    "polyline_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "35cb5af4-fcab-42a1-a808-106a024d2889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87084125, 20.21932158,  0.87308075, 19.28813237,  1.        ,\n",
       "         0.05001476,  0.        ],\n",
       "       [ 0.87308075, 19.28813237,  0.86913281, 18.27315992,  1.        ,\n",
       "         0.14828724,  0.        ],\n",
       "       [ 0.86913281, 18.27315992,  0.82474593, 17.49473437,  1.        ,\n",
       "         0.24652916,  0.        ],\n",
       "       [ 0.82474593, 17.49473437,  0.76565395, 16.66880652,  1.        ,\n",
       "         0.34751931,  0.        ],\n",
       "       [ 0.76565395, 16.66880652,  0.76006989, 15.6344186 ,  1.        ,\n",
       "         0.45051929,  0.        ],\n",
       "       [ 0.76006989, 15.6344186 ,  0.70801954, 14.76012334,  1.        ,\n",
       "         0.55247495,  0.        ],\n",
       "       [ 0.70801954, 14.76012334,  0.66453049, 13.81127604,  1.        ,\n",
       "         0.64971468,  0.        ],\n",
       "       [ 0.66453049, 13.81127604,  0.61970006, 12.87656481,  1.        ,\n",
       "         0.74834853,  0.        ],\n",
       "       [ 0.61970006, 12.87656481,  0.56796328, 11.894135  ,  1.        ,\n",
       "         0.84861705,  0.        ],\n",
       "       [ 0.56796328, 11.894135  ,  0.53740644, 10.77412503,  1.        ,\n",
       "         0.94998512,  0.        ],\n",
       "       [ 0.53740644, 10.77412503,  0.47819266,  9.83542617,  1.        ,\n",
       "         1.04910401,  0.        ],\n",
       "       [ 0.47819266,  9.83542617,  0.40018414,  8.65608088,  1.        ,\n",
       "         1.14626342,  0.        ],\n",
       "       [ 0.40018414,  8.65608088,  0.33285176,  7.45468512,  1.        ,\n",
       "         1.24721968,  0.        ],\n",
       "       [ 0.33285176,  7.45468512,  0.24573554,  6.36633027,  1.        ,\n",
       "         1.34778619,  0.        ],\n",
       "       [ 0.24573554,  6.36633027,  0.20638393,  5.09424328,  1.        ,\n",
       "         1.44763362,  0.        ],\n",
       "       [ 0.20638393,  5.09424328,  0.17639484,  3.77883677,  1.        ,\n",
       "         1.54743767,  0.        ],\n",
       "       [ 0.17639484,  3.77883677,  0.05610294,  2.95042701,  1.        ,\n",
       "         1.64684683,  0.        ],\n",
       "       [ 0.05610294,  2.95042701, -0.02539481,  1.65746267,  1.        ,\n",
       "         1.74828607,  0.        ],\n",
       "       [-0.02539481,  1.65746267,  0.        ,  0.        ,  1.        ,\n",
       "         1.85095701,  0.        ]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "20598be8-2360-4c5b-bc55-3a59d7e6ec89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 7)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b2fad73b-a649-4315-90d0-fa3bdcf8d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding obj feature\n",
    "# obj_feature_ls: a list of each object features, [[object1 features], [object2 features], ...]\n",
    "for obj_feature in obj_feature_ls:\n",
    "    obj_len = obj_feature[0].shape[0] # xys # of timesteps\n",
    "    # if not obj_feature[2].shape[0] == obj_len:\n",
    "    #     from pdb import set_trace;set_trace()\n",
    "    obj_nd = np.hstack((obj_feature[0], np.zeros(\n",
    "        (obj_len, 1)), obj_feature[2].reshape((-1, 1)), np.ones((obj_len, 1)) * polyline_id))\n",
    "    assert obj_nd.shape[1] == 7, \"obj_traj feature dim 1 is not correct\"\n",
    "    traj_nd = np.vstack((traj_nd, obj_nd))\n",
    "\n",
    "    traj_id2mask[polyline_id] = (pre_traj_len, traj_nd.shape[0])\n",
    "    pre_traj_len = traj_nd.shape[0]\n",
    "    polyline_id += 1\n",
    "\n",
    "# encoding lane feature\n",
    "# lane_feature_ls: a list of lane features, [[lane1 features], [lane2 features], ...]\n",
    "pre_lane_len = lane_nd.shape[0]\n",
    "for lane_feature in lane_feature_ls:\n",
    "    l_lane_len = lane_feature[0].shape[0]\n",
    "    l_lane_nd = np.hstack(\n",
    "        (lane_feature[0], np.ones((l_lane_len, 1)) * polyline_id))\n",
    "    assert l_lane_nd.shape[1] == 7, \"l_lane_traj feature dim 1 is not correct\"\n",
    "    lane_nd = np.vstack((lane_nd, l_lane_nd))\n",
    "    lane_id2mask[polyline_id] = (pre_lane_len, lane_nd.shape[0])\n",
    "    _tmp_len_1 = pre_lane_len - lane_nd.shape[0]\n",
    "    pre_lane_len = lane_nd.shape[0]\n",
    "    polyline_id += 1\n",
    "\n",
    "    r_lane_len = lane_feature[1].shape[0]\n",
    "    r_lane_nd = np.hstack(\n",
    "        (lane_feature[1], np.ones((r_lane_len, 1)) * polyline_id)\n",
    "    )\n",
    "    assert r_lane_nd.shape[1] == 7, \"r_lane_traj feature dim 1 is not correct\"\n",
    "    lane_nd = np.vstack((lane_nd, r_lane_nd))\n",
    "    lane_id2mask[polyline_id] = (pre_lane_len, lane_nd.shape[0])\n",
    "    _tmp_len_2 = pre_lane_len - lane_nd.shape[0]\n",
    "    pre_lane_len = lane_nd.shape[0]\n",
    "    polyline_id += 1\n",
    "\n",
    "    assert _tmp_len_1 == _tmp_len_2, f\"left, right lane vector length contradict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "48c30004-b34b-4f81-b8f8-1224d7cc021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hallucinated_lane_1 shape per lane_id:  (9, 6)\n",
      "total number of lane_ids:  27\n",
      "length of lane_nd should be:  486\n"
     ]
    }
   ],
   "source": [
    "print('hallucinated_lane_1 shape per lane_id: ', lane_feature_ls[0][0].shape)\n",
    "print('total number of lane_ids: ', len(lane_feature_ls))\n",
    "print('length of lane_nd should be: ', lane_feature_ls[0][0].shape[0] * len(lane_feature_ls) * 2) # 2 because hallucinated_lane_1 and hallucinated_lane_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d486accd-0e06-483c-af48-9c32061ec3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 7)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a5b3bc66-c999-4dc8-8659-40271b55ed26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-43.43728575,   7.99502789,          nan, ...,   8.07058635,\n",
       "                 nan,   1.        ],\n",
       "       [-41.79696723,   8.07058635,          nan, ...,   8.14614481,\n",
       "                 nan,   1.        ],\n",
       "       [-40.15664872,   8.14614481,          nan, ...,   8.22170327,\n",
       "                 nan,   1.        ],\n",
       "       ...,\n",
       "       [-18.19594656,   5.27154567,          nan, ...,   5.35503996,\n",
       "                 nan,  54.        ],\n",
       "       [-16.48032636,   5.35503996,          nan, ...,   5.43853425,\n",
       "                 nan,  54.        ],\n",
       "       [-14.76470616,   5.43853425,          nan, ...,   5.52202854,\n",
       "                 nan,  54.        ]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "38d8d70e-ce71-463e-a777-46eb3a4a3787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/kgl4y9fx4rq74cpn9vmn91j40000gn/T/ipykernel_14957/2656644933.py:1: RuntimeWarning: Mean of empty slice\n",
      "  col_mean = np.nanmean(lane_nd, axis=0)\n"
     ]
    }
   ],
   "source": [
    "col_mean = np.nanmean(lane_nd, axis=0)\n",
    "if np.isnan(col_mean).any():\n",
    "    lane_nd[:, 2].fill(.0)\n",
    "    lane_nd[:, 5].fill(.0)\n",
    "else:\n",
    "    inds = np.where(np.isnan(lane_nd))\n",
    "    lane_nd[inds] = np.take(col_mean, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f32b4536-0709-4e9f-8f7d-0d103f43e1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.05269328, 11.65601556,         nan, -1.88652533, 10.5182771 ,\n",
       "               nan, 27.5       ])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "37162be9-4e22-4cac-801b-4652587068fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-43.43728575,   7.99502789,   0.        , ...,   8.07058635,\n",
       "          0.        ,   1.        ],\n",
       "       [-41.79696723,   8.07058635,   0.        , ...,   8.14614481,\n",
       "          0.        ,   1.        ],\n",
       "       [-40.15664872,   8.14614481,   0.        , ...,   8.22170327,\n",
       "          0.        ,   1.        ],\n",
       "       ...,\n",
       "       [-18.19594656,   5.27154567,   0.        , ...,   5.35503996,\n",
       "          0.        ,  54.        ],\n",
       "       [-16.48032636,   5.35503996,   0.        , ...,   5.43853425,\n",
       "          0.        ,  54.        ],\n",
       "       [-14.76470616,   5.43853425,   0.        , ...,   5.52202854,\n",
       "          0.        ,  54.        ]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4270ba-b291-413b-b0d8-3165f46cb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_gt_offset_format function is explained below\n",
    "offset_gt = trans_gt_offset_format(gt) # returns offsets. [ [gt[1] - gt[0]], [ gt[2] -g t[1] ], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "427094ba-de0f-40c1-bc05-1f84adccffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the features are:\n",
    "# (xs, ys, xe, ye, obejct_type, timestamp(avg_for_start_end?),polyline_id) for object\n",
    "# (xs, ys, zs, xe, ye, ze, polyline_id) for lanes\n",
    "\n",
    "# change lanes feature to xs, ys, xe, ye, NULL, zs, ze, polyline_id)\n",
    "lane_nd = np.hstack([lane_nd, np.zeros((lane_nd.shape[0], 1), dtype=lane_nd.dtype)])\n",
    "lane_nd = lane_nd[:, [0, 1, 3, 4, 7, 2, 5, 6]]\n",
    "# change object features to (xs, ys, xe, ye, timestamp, NULL, NULL, polyline_id)\n",
    "traj_nd = np.hstack([traj_nd, np.zeros((traj_nd.shape[0], 2), dtype=traj_nd.dtype)])\n",
    "traj_nd = traj_nd[:, [0, 1, 2, 3, 5, 7, 8, 6]]\n",
    "\n",
    "# don't ignore the id\n",
    "polyline_features = np.vstack((traj_nd, lane_nd))\n",
    "data = [[polyline_features.astype(np.float32), offset_gt, traj_id2mask, lane_id2mask, traj_nd.shape[0], lane_nd.shape[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9796453a-bbcb-4339-9460-20170b40ab40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.87084125,  20.21932158,   0.87308075, ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.87308075,  19.28813237,   0.86913281, ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.86913281,  18.27315992,   0.82474593, ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       ...,\n",
       "       [-18.19594656,   5.27154567, -16.48032636, ...,   0.        ,\n",
       "          0.        ,  54.        ],\n",
       "       [-16.48032636,   5.35503996, -14.76470616, ...,   0.        ,\n",
       "          0.        ,  54.        ],\n",
       "       [-14.76470616,   5.43853425, -13.04908596, ...,   0.        ,\n",
       "          0.        ,  54.        ]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyline_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "51978861-69da-4a99-82cb-1be6ee7db4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed0d3b-9313-45e0-b1a1-f0192d4ed4c5",
   "metadata": {},
   "source": [
    "### 2.1 trans_gt_offset_format function in feature_utils.py\n",
    "```\n",
    "trans_gt_offset_format(gt)\n",
    "```\n",
    "- this function is called inside encoding_features function\n",
    "-  returns offset_gt which represents per-stepcoordinate offsets, starting from the last observed location. We rotate the coordinate system based on the heading of the target vehicle at the last observed location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a99daa-7bf2-40af-b154-6cc7a59e7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_gt_offset_format(gt):\n",
    "    \"\"\"\n",
    "    >Our predicted trajectories are parameterized as per-stepcoordinate offsets, starting from the last observed location.We rotate the coordinate system based on the heading of the target vehicle at the last observed location.\n",
    "    \n",
    "    \"\"\"\n",
    "    assert gt.shape == (30, 2) or gt.shape == (0, 2), f\"{gt.shape} is wrong\"\n",
    "\n",
    "    # for test, no gt, just return a (0, 2) ndarray\n",
    "    if gt.shape == (0, 2):\n",
    "        return gt\n",
    "\n",
    "    offset_gt = np.vstack((gt[0], gt[1:] - gt[:-1]))\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    assert (offset_gt.cumsum(axis=0) -\n",
    "            gt).sum() < 1e-6, f\"{(offset_gt.cumsum(axis=0) -gt).sum()}\"\n",
    "\n",
    "    return offset_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a74541cc-38cc-4251-a005-9cdd1540909b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.41191360e-01, -7.25470306e-01],\n",
       "       [-1.94483338e-01, -2.09854082e+00],\n",
       "       [-2.63776742e-01, -3.21874101e+00],\n",
       "       [-2.95501797e-01, -4.53486013e+00],\n",
       "       [-3.16634870e-01, -5.82386836e+00],\n",
       "       [-3.68211708e-01, -7.21845016e+00],\n",
       "       [-3.39067141e-01, -8.55146026e+00],\n",
       "       [-3.58316458e-01, -9.95174055e+00],\n",
       "       [-3.40818869e-01, -1.14272523e+01],\n",
       "       [-3.53501353e-01, -1.29405419e+01],\n",
       "       [-3.22657885e-01, -1.43041238e+01],\n",
       "       [-2.88234570e-01, -1.57339501e+01],\n",
       "       [-3.01689465e-01, -1.72973049e+01],\n",
       "       [-2.70060718e-01, -1.88551640e+01],\n",
       "       [-2.29726641e-01, -2.03349161e+01],\n",
       "       [-1.84780898e-01, -2.18480218e+01],\n",
       "       [-1.61741405e-01, -2.34479923e+01],\n",
       "       [-1.13788993e-01, -2.49812366e+01],\n",
       "       [-4.65114205e-02, -2.65540997e+01],\n",
       "       [ 1.25489165e-03, -2.80560183e+01],\n",
       "       [ 1.64995721e-02, -2.96354387e+01],\n",
       "       [ 8.82846529e-02, -3.13419149e+01],\n",
       "       [ 1.62935407e-01, -3.30333472e+01],\n",
       "       [ 2.24425748e-01, -3.45357446e+01],\n",
       "       [ 2.70486303e-01, -3.62170440e+01],\n",
       "       [ 3.21535688e-01, -3.77763250e+01],\n",
       "       [ 3.85195857e-01, -3.94363051e+01],\n",
       "       [ 4.66357331e-01, -4.11989351e+01],\n",
       "       [ 5.18434700e-01, -4.28006135e+01],\n",
       "       [ 5.87126147e-01, -4.44029631e+01]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "17ad7c3d-a687-4507-8f61-6334046c9e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14119136, -0.72547031],\n",
       "       [-0.05329198, -1.37307051],\n",
       "       [-0.0692934 , -1.12020019],\n",
       "       [-0.03172505, -1.31611912],\n",
       "       [-0.02113307, -1.28900823],\n",
       "       [-0.05157684, -1.3945818 ],\n",
       "       [ 0.02914457, -1.3330101 ],\n",
       "       [-0.01924932, -1.40028029],\n",
       "       [ 0.01749759, -1.47551175],\n",
       "       [-0.01268248, -1.51328964],\n",
       "       [ 0.03084347, -1.36358189],\n",
       "       [ 0.03442331, -1.4298263 ],\n",
       "       [-0.01345489, -1.56335479],\n",
       "       [ 0.03162875, -1.55785907],\n",
       "       [ 0.04033408, -1.47975212],\n",
       "       [ 0.04494574, -1.51310568],\n",
       "       [ 0.02303949, -1.59997052],\n",
       "       [ 0.04795241, -1.53324427],\n",
       "       [ 0.06727757, -1.57286311],\n",
       "       [ 0.04776631, -1.50191862],\n",
       "       [ 0.01524468, -1.57942041],\n",
       "       [ 0.07178508, -1.7064762 ],\n",
       "       [ 0.07465075, -1.69143224],\n",
       "       [ 0.06149034, -1.50239741],\n",
       "       [ 0.04606056, -1.68129941],\n",
       "       [ 0.05104938, -1.55928098],\n",
       "       [ 0.06366017, -1.65998015],\n",
       "       [ 0.08116147, -1.76263002],\n",
       "       [ 0.05207737, -1.60167831],\n",
       "       [ 0.06869145, -1.60234963]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_gt = np.vstack((gt[0], gt[1:] - gt[:-1]))\n",
    "offset_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1bbf990d-c962-4c13-97d3-64eef72341a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(offset_gt.cumsum(axis=0) - gt).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517f2dd-d312-42b2-b1c3-e32a77596792",
   "metadata": {},
   "source": [
    "## 3. save_features in feature_utils.py function explanation\n",
    "```\n",
    "save_features(feature_df, name, dir_=None)\n",
    "```\n",
    "\n",
    "- It is called inside the preprocess_data.py\n",
    "- saves the feature_df into .pkl\n",
    "- Last step of preprocessing data\n",
    "- These preprocessed data (.pkl files) are later used in GraphDataset object in dataset.py to convert into tensors and being batchfied for model feeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17a25b-0331-4c38-9fcf-a55f787c5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(df, name, dir_=None):\n",
    "    if dir_ is None:\n",
    "        dir_ = './input_data'\n",
    "    if not os.path.exists(dir_):\n",
    "        os.makedirs(dir_)\n",
    "\n",
    "    name = f\"features_{name}.pkl\"\n",
    "    df.to_pickle(\n",
    "        os.path.join(dir_, name)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.8 vectornet",
   "language": "python",
   "name": "py308vectornet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
